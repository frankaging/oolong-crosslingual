{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playground for our experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stanza Pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "# stanza.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-28 02:09:36 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2021-06-28 02:09:36 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "========================\n",
      "\n",
      "2021-06-28 02:09:37 INFO: Use device: gpu\n",
      "2021-06-28 02:09:37 INFO: Loading: tokenize\n",
      "2021-06-28 02:09:49 INFO: Loading: pos\n",
      "2021-06-28 02:09:53 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('en', processors='tokenize,mwt,pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Barack', 'PROPN', 'NNP'),\n",
       " ('Obama', 'PROPN', 'NNP'),\n",
       " (',', 'PUNCT', ','),\n",
       " ('he', 'PRON', 'PRP'),\n",
       " ('was', 'AUX', 'VBD'),\n",
       " ('born', 'VERB', 'VBN'),\n",
       " ('in', 'ADP', 'IN'),\n",
       " ('Hawaii', 'PROPN', 'NNP'),\n",
       " ('.', 'PUNCT', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_postag_token(sentence_in):\n",
    "    ret = []\n",
    "    doc = nlp(sentence_in)\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            ret  += [(word.text, word.upos, word.xpos,)]\n",
    "    return ret\n",
    "\n",
    "get_postag_token('Barack Obama, he was born in Hawaii.')\n",
    "\n",
    "type_to_include = ['PROPN', 'NOUN'] # proper n + n ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan\n"
     ]
    }
   ],
   "source": [
    "syns = wordnet.synsets(\"program\")\n",
    "print(syns[0].lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('plan.n.01'),\n",
       " Synset('program.n.02'),\n",
       " Synset('broadcast.n.02'),\n",
       " Synset('platform.n.02'),\n",
       " Synset('program.n.05'),\n",
       " Synset('course_of_study.n.01'),\n",
       " Synset('program.n.07'),\n",
       " Synset('program.n.08'),\n",
       " Synset('program.v.01'),\n",
       " Synset('program.v.02')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Galactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All these are in shell script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: gd-translate [-h] [--input INPUT] [--spec SPEC] [--mem MEM]\r\n",
      "                    [--output OUTPUT] [--seed SEED] [--verbose VERBOSE]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help         show this help message and exit\r\n",
      "  --input INPUT      Input treebank for training\r\n",
      "  --spec SPEC\r\n",
      "  --mem MEM          Memory for translating. (default=8g)\r\n",
      "  --output OUTPUT    Ontput treebank after permutation: (default) input-\r\n",
      "                     spec.conllu\r\n",
      "  --seed SEED        Random seed\r\n",
      "  --verbose VERBOSE  Verbosity level\r\n"
     ]
    }
   ],
   "source": [
    "! GALACTIC_ROOT=./submodules/gdtreebank ./submodules/gdtreebank/bin/gd-translate --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -cp ./submodules/gdtreebank//bin/gdgen.jar -Xmx8g datagen.GalacticGen --task test --inputTB ./submodules/gdtreebank/toy/sample.conllu --outputTB ./submodules/gdtreebank/toy/sample-en~fr@N~hi@V.conllu --verbose 1 --seed 0 --supStrateModelNOUN ./submodules/gdtreebank//models/GD_French/fr@N.orm --subStrateModelNOUN ./submodules/gdtreebank//models/GD_English/en@N.orm --supStrateModelVERB ./submodules/gdtreebank//models/GD_Hindi/hi@V.orm --subStrateModelVERB ./submodules/gdtreebank//models/GD_English/en@V.orm\r\n",
      "/bin/sh: 1: java: not found\r\n"
     ]
    }
   ],
   "source": [
    "! GALACTIC_ROOT=./submodules/gdtreebank/ ./submodules/gdtreebank/bin/gd-translate --input ./submodules/gdtreebank/toy/sample.conllu --spec en~fr@N~hi@V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
